{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28894ab0-1fa0-4db6-84f5-23e055f91b6f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Designing end to end pipeline assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f160f31-d740-4cb6-8ffa-1aebf0edf6be",
   "metadata": {},
   "source": [
    "## Step 1 - Transcribe voice to text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c014b9-5c68-4f44-8f37-bdaac19934f8",
   "metadata": {},
   "source": [
    "### Setup and installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c44e11f5-5d23-4a15-8eb3-546c8d78557e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in c:\\users\\navsi\\anaconda3\\lib\\site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from librosa) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from librosa) (1.10.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from librosa) (1.2.1)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from librosa) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\navsi\\appdata\\roaming\\python\\python310\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from librosa) (0.56.4)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from librosa) (1.4.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from librosa) (0.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from librosa) (4.12.2)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from lazy-loader>=0.1->librosa) (24.1)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (0.39.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (65.6.3)\n",
      "Requirement already satisfied: requests in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (2.28.1)\n",
      "Requirement already satisfied: appdirs in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (1.4.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from requests->pooch>=1.1->librosa) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from requests->pooch>=1.1->librosa) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from requests->pooch>=1.1->librosa) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from requests->pooch>=1.1->librosa) (2022.12.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in c:\\users\\navsi\\anaconda3\\lib\\site-packages (0.25.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webrtcvad in c:\\users\\navsi\\anaconda3\\lib\\site-packages (2.0.10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to c:\\users\\navsi\\appdata\\local\\temp\\pip-req-build-gk4zopov\n",
      "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numba in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from openai-whisper==20231117) (0.56.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from openai-whisper==20231117) (1.23.5)\n",
      "Requirement already satisfied: torch in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from openai-whisper==20231117) (1.12.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from openai-whisper==20231117) (4.64.1)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from openai-whisper==20231117) (10.4.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from openai-whisper==20231117) (0.7.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from numba->openai-whisper==20231117) (0.39.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from numba->openai-whisper==20231117) (65.6.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from tiktoken->openai-whisper==20231117) (2022.7.9)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from tiktoken->openai-whisper==20231117) (2.28.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from torch->openai-whisper==20231117) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\navsi\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->openai-whisper==20231117) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2022.12.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git 'C:\\Users\\navsi\\AppData\\Local\\Temp\\pip-req-build-gk4zopov'\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa\n",
    "!pip install pydub\n",
    "!pip install webrtcvad\n",
    "!pip install git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01ad73e-bffc-4b9e-a469-04ad4c08e58f",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1e92757-14ca-41ec-a99c-48395b013b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg-downloader in c:\\users\\navsi\\anaconda3\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from ffmpeg-downloader) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.40.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from ffmpeg-downloader) (4.64.1)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\navsi\\appdata\\roaming\\python\\python310\\site-packages (from ffmpeg-downloader) (3.10.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from ffmpeg-downloader) (24.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\navsi\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.40.0->ffmpeg-downloader) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from requests->ffmpeg-downloader) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from requests->ffmpeg-downloader) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from requests->ffmpeg-downloader) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from requests->ffmpeg-downloader) (2022.12.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install ffmpeg-downloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "100b2451-56a2-477e-9d58-0b7530127def",
   "metadata": {},
   "outputs": [],
   "source": [
    "import webrtcvad\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "import whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d03213b-3a62-48ae-aa00-e0e75ba6eaf7",
   "metadata": {},
   "source": [
    "## Voice Activity Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20061dfa-f227-4628-b3f7-8ea26a1a42fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_vad(audio_data, sample_rate, vad_mode=0):\n",
    "    vad = webrtcvad.Vad(vad_mode)\n",
    "    frame_duration = 30 #ms\n",
    "    frame_size = int(sample_rate * frame_duration /1000)\n",
    "    audio_data = np.frombuffer(audio_data, dtype=np.int16)\n",
    "    \n",
    "    if len(audio_data) % frame_size !=0:\n",
    "        padding_size = frame_size - (len(audio_data) % frame_size)\n",
    "        audio_data = np.pad(audio_data, (0, padding_size),'constant',constant_values=0)\n",
    "        \n",
    "    frames = [audio_data[i:i + frame_size] for i in range(0, len(audio_data), frame_size)]\n",
    "    voiced_frames = [frame.tobytes() for frame in frames if vad.is_speech(frame.tobytes(),sample_rate)]\n",
    "    return b''.join(voiced_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d784466f-e7a4-421d-8bd1-4c96fa939db1",
   "metadata": {},
   "source": [
    "## Audio preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "30bc7f22-4e52-4bc0-8ed5-fa6239d10fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(file_path, target_sample_rate=16000):\n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "    audio = audio.set_frame_rate(target_sample_rate).set_channels(1)\n",
    "    audio_data = audio.raw_data\n",
    "    audio_data = apply_vad(audio_data,target_sample_rate)\n",
    "    return audio_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d553c9-a72b-4100-951d-b74d321f242c",
   "metadata": {},
   "source": [
    "## Saving processed audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee035d0f-a686-49be-b4d9-d69352be26b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_temp_audio(audio_data,temp_path=\"temp.wav\", sample_rate=16000):\n",
    "    audio_segment = AudioSegment(\n",
    "        data=audio_data,\n",
    "        sample_width=2,\n",
    "        frame_rate=sample_rate,\n",
    "        channels=1\n",
    "    )\n",
    "    audio_segment.export(temp_path,format=\"wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b914a9-2b7b-4f66-9708-2468174e3aea",
   "metadata": {},
   "source": [
    "## Audio transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f208b9a5-2fe8-4a51-99d5-ad1b144ae36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(file_path):\n",
    "    model = whisper.load_model(\"base\")\n",
    "    result = model.transcribe(file_path)\n",
    "    return result[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2b5758-0ca4-497f-a6ef-262523b8d0a9",
   "metadata": {},
   "source": [
    "## Testing the Whisper model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d801124a-d6d0-4d5d-9d39-c4f360bca90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Who is the president of India?\n"
     ]
    }
   ],
   "source": [
    "audio_data = preprocess_audio(\"Recording.mp3\")\n",
    "save_temp_audio(audio_data)\n",
    "transcription = transcribe_audio(\"temp.wav\")\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741f54bf-ba30-4b10-983a-8cfd2c954306",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step 2 - Generate a response by giving the transcribed text to a LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c327844a-c687-4843-a81b-715dd787da04",
   "metadata": {},
   "source": [
    "### setup and installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ecce8038-e61d-48ff-898a-6bee0695157e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\navsi\\anaconda3\\lib\\site-packages (0.2.14)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langchain) (3.10.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.32 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langchain) (0.2.35)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langchain) (0.1.104)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langchain) (2.28.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.32->langchain) (2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-cpp-python in c:\\users\\navsi\\anaconda3\\lib\\site-packages (0.2.89)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from llama-cpp-python) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from llama-cpp-python) (1.23.5)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from llama-cpp-python) (5.6.3)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from llama-cpp-python) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\navsi\\anaconda3\\lib\\site-packages (4.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from pypdf) (4.12.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in c:\\users\\navsi\\anaconda3\\lib\\site-packages (0.2.12)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langchain_community) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langchain_community) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langchain_community) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.13 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langchain_community) (0.2.14)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.30 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langchain_community) (0.2.35)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langchain_community) (0.1.104)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langchain_community) (1.23.5)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langchain_community) (2.28.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langchain_community) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langchain<0.3.0,>=0.2.13->langchain_community) (0.2.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langchain<0.3.0,>=0.2.13->langchain_community) (2.8.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2022.12.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (2.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (3.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.30->langchain_community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain_community) (2.20.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (0.4.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install llama-cpp-python\n",
    "!pip install pypdf\n",
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a60fec9d-4c3b-4c38-9150-6798b290f27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import LlamaCpp\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90129ed3-5fae-458b-b2f9-8f711215ee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2b12f4d9-b328-4a48-a958-ce9cb74785a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 32 key-value pairs and 291 tensors from C:\\Users\\navsi\\Downloads\\llama-2-7b-chat-hf-q2_k.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Llama 2 7b Chat Hf\n",
      "llama_model_loader: - kv   3:                       general.organization str              = Meta Llama\n",
      "llama_model_loader: - kv   4:                           general.finetune str              = chat-hf\n",
      "llama_model_loader: - kv   5:                           general.basename str              = Llama-2\n",
      "llama_model_loader: - kv   6:                         general.size_label str              = 7B\n",
      "llama_model_loader: - kv   7:                            general.license str              = llama2\n",
      "llama_model_loader: - kv   8:                               general.tags arr[str,6]       = [\"facebook\", \"meta\", \"pytorch\", \"llam...\n",
      "llama_model_loader: - kv   9:                          general.languages arr[str,1]       = [\"en\"]\n",
      "llama_model_loader: - kv  10:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv  11:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv  12:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv  13:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv  14:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv  15:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv  16:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  17:                          general.file_type u32              = 10\n",
      "llama_model_loader: - kv  18:                           llama.vocab_size u32              = 32000\n",
      "llama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = default\n",
      "llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  23:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  24:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  27:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  28:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  29:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  30:                    tokenizer.chat_template str              = {% if messages[0]['role'] == 'system'...\n",
      "llama_model_loader: - kv  31:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q2_K:  129 tensors\n",
      "llama_model_loader: - type q3_K:   96 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens cache size = 3\n",
      "llm_load_vocab: token to piece cache size = 0.1684 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
      "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q2_K - Medium\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 2.36 GiB (3.01 BPW) \n",
      "llm_load_print_meta: general.name     = Llama 2 7b Chat Hf\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: max token length = 48\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
      "llm_load_tensors:        CPU buffer size =  2414.82 MiB\n",
      ".................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2048\n",
      "llama_new_context_with_model: n_batch    = 1024\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =  1024.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 1024.00 MiB, K (f16):  512.00 MiB, V (f16):  512.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   164.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.name': 'Llama 2 7b Chat Hf', 'general.architecture': 'llama', 'general.type': 'model', 'llama.context_length': '4096', 'general.organization': 'Meta Llama', 'general.basename': 'Llama-2', 'general.finetune': 'chat-hf', 'general.size_label': '7B', 'general.license': 'llama2', 'llama.block_count': '32', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '2', 'general.file_type': '10', 'llama.attention.head_count_kv': '32', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.vocab_size': '32000', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.model': 'llama', 'tokenizer.ggml.pre': 'default', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.chat_template': \"{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if loop.index0 == 0 and system_message != false %}{% set content = '<<SYS>>\\\\n' + system_message + '\\\\n<</SYS>>\\\\n\\\\n' + message['content'] %}{% else %}{% set content = message['content'] %}{% endif %}{% if message['role'] == 'user' %}{{ bos_token + '[INST] ' + content.strip() + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ ' '  + content.strip() + ' ' + eos_token }}{% endif %}{% endfor %}\"}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if loop.index0 == 0 and system_message != false %}{% set content = '<<SYS>>\\n' + system_message + '\\n<</SYS>>\\n\\n' + message['content'] %}{% else %}{% set content = message['content'] %}{% endif %}{% if message['role'] == 'user' %}{{ bos_token + '[INST] ' + content.strip() + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ ' '  + content.strip() + ' ' + eos_token }}{% endif %}{% endfor %}\n",
      "Using chat eos_token: </s>\n",
      "Using chat bos_token: <s>\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import LlamaCpp\n",
    "\n",
    "\n",
    "model_path = r\"C:\\Users\\navsi\\Downloads\\llama-2-7b-chat-hf-q2_k.gguf\"\n",
    "\n",
    "callback = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "n_gpu_layers = 100\n",
    "n_batch = 1024\n",
    "\n",
    "llm = LlamaCpp(\n",
    "    model_path=model_path,\n",
    "    temperature=0.7,  # Slightly lower for more deterministic responses\n",
    "    n_gpu_layers=n_gpu_layers,  # Adjust based on GPU memory\n",
    "    n_batch=n_batch,  # Reduce batch size if memory is constrained\n",
    "    n_ctx=2048,  # Lower context size if you have memory constraints\n",
    "    max_tokens=35,  # Shorter outputs\n",
    "    top_p=0.7,  # Restrict token set slightly\n",
    "    callback_manager=callback,\n",
    "    verbose=True,  # Disable verbose if not needed\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4684eab-fb06-4b0c-97fa-ce715e67e4d4",
   "metadata": {},
   "source": [
    "## Text Processing with Llama2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6769beb0-02a7-4c7e-8061-f2d290726da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Answer the following text delimited by triple backtricks in 2 sentences:\n",
    "```{text}```\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=text, input_variables=[\"text\"])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "def process_text_input(user_input):\n",
    "    \"\"\"\n",
    "    Process user input using Llama model.\n",
    "    \n",
    "    Args:\n",
    "        user_input (str): Input text.\n",
    "    Returns:\n",
    "        str: Response text.\n",
    "    \"\"\"\n",
    "    response = llm_chain({\"text\": user_input})\n",
    "    actual_text = response['text']\n",
    "    return actual_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f35b65-f32e-48a6-af46-9c65bade9c57",
   "metadata": {},
   "source": [
    "## Testing the Llama2 model on a Example text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c711a2a2-4d2f-47f2-929a-af14e31ad0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the text:  what should i eat for dinner?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 9 prefix-match hit, remaining 7 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and output: \"You could try having a nice salad with grilled chicken or a hearty pasta dish with a side of garlic bread. hopefully something"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    2414.61 ms\n",
      "llama_print_timings:      sample time =      21.89 ms /    35 runs   (    0.63 ms per token,  1598.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     917.55 ms /     7 tokens (  131.08 ms per token,     7.63 tokens per second)\n",
      "llama_print_timings:        eval time =    8272.76 ms /    34 runs   (  243.32 ms per token,     4.11 tokens per second)\n",
      "llama_print_timings:       total time =    9397.08 ms /    41 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Response:\n",
      " and output: \"You could try having a nice salad with grilled chicken or a hearty pasta dish with a side of garlic bread. hopefully something\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    user_input = input(\"Enter the text: \")\n",
    "    if user_input:\n",
    "        response_text = process_text_input(user_input)\n",
    "        print(\"Generated Response:\")\n",
    "        print(response_text)\n",
    "    else:\n",
    "        print(\"Please provide some input.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83161df5-3106-482d-a0e8-1daa58a23548",
   "metadata": {},
   "source": [
    "# Step 3 - Converting generated text respponse back into speech."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc121fe-0754-41fe-a3b1-c64f50e40083",
   "metadata": {},
   "source": [
    "### Set up and installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "35a3ff38-9589-48fb-9bc9-41c9e3d0ffbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting edge-tts\n",
      "  Downloading edge_tts-6.1.12-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: aiohttp>=3.8.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from edge-tts) (3.10.5)\n",
      "Collecting certifi>=2023.11.17 (from edge-tts)\n",
      "  Downloading certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from aiohttp>=3.8.0->edge-tts) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from aiohttp>=3.8.0->edge-tts) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from aiohttp>=3.8.0->edge-tts) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from aiohttp>=3.8.0->edge-tts) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from aiohttp>=3.8.0->edge-tts) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from aiohttp>=3.8.0->edge-tts) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from aiohttp>=3.8.0->edge-tts) (4.0.3)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp>=3.8.0->edge-tts) (3.4)\n",
      "Downloading edge_tts-6.1.12-py3-none-any.whl (29 kB)\n",
      "Downloading certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "   ---------------------------------------- 0.0/163.0 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 61.4/163.0 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 163.0/163.0 kB 2.0 MB/s eta 0:00:00\n",
      "Installing collected packages: certifi, edge-tts\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2022.12.7\n",
      "    Uninstalling certifi-2022.12.7:\n",
      "      Successfully uninstalled certifi-2022.12.7\n",
      "Successfully installed certifi-2024.7.4 edge-tts-6.1.12\n",
      "Collecting asyncio\n",
      "  Downloading asyncio-3.4.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "Downloading asyncio-3.4.3-py3-none-any.whl (101 kB)\n",
      "   ---------------------------------------- 0.0/101.8 kB ? eta -:--:--\n",
      "   ------------------------ --------------- 61.4/101.8 kB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 101.8/101.8 kB 1.5 MB/s eta 0:00:00\n",
      "Installing collected packages: asyncio\n",
      "Successfully installed asyncio-3.4.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install edge-tts\n",
    "!pip install asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d726937-7a74-4b22-a7b1-606996840110",
   "metadata": {},
   "source": [
    "### Importing llibraris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4809ffd6-d3de-4d9e-869a-273b20cb4a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import edge_tts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58832c85-325a-4752-b0cd-29478542da6c",
   "metadata": {},
   "source": [
    "## Text to speech conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c256287b-f6a4-40fd-9472-600d7c795f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def text_to_speech(text: str, voice: str,output_file: str):\n",
    "    communicate = edge_tts.Communicate(text, voice)\n",
    "    await communicate.save(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d03729-7834-4d63-ab4a-62fc5c47ecaa",
   "metadata": {},
   "source": [
    "## Testing the edge TTS model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a46308f4-892f-4e19-9883-9da3876abeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOICES = ['en-US-GuyNeural', 'en-US-JennyNueral']\n",
    "TEXT = \"I just want to go home and sleep.\"\n",
    "VOICE = VOICES[0]\n",
    "OUTPUT_FILE = \"test.mp3\"\n",
    "\n",
    "await text_to_speech(TEXT, VOICE, OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b9db884f-bf01-4a16-a6b6-e6ec9619fa5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Audio\n",
    "display(Audio(OUTPUT_FILE,autoplay=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea28cc0a-7bba-45ac-bd3b-43fe25519b6c",
   "metadata": {},
   "source": [
    "# Step 4 - Creating pipeline for connecting all models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10197653-b3c7-4880-8d94-c6a8841c9162",
   "metadata": {},
   "source": [
    "### Creating a wrapper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "123f58ca-d541-467b-ab64-2fd5d4e9c4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def text_to_speech(text: str, voice:str, output_file: str):\n",
    "    communicate = edge_tts.Communicate(text, voice)\n",
    "    await communicate.save(output_file)\n",
    "    \n",
    "def text_to_speech_wrapper(text: str,voice:str,output_file:str):\n",
    "    asyncio.run(text_to_speech(text, voice,output_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fae813-2a5f-4e0d-9cbd-8f0aa703a1ea",
   "metadata": {},
   "source": [
    "### Creating a pipeline function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5483ad40-f44b-45e6-adfb-c49cc64aa16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(audio_file):\n",
    "    audio_data = preprocess_audio(audio_file)\n",
    "    save_temp_audio(audio_data)\n",
    "    trnascription = transcribe_audio(\"temp.wav\")\n",
    "                                     \n",
    "    answer = process_text_input(transcription)\n",
    "                                     \n",
    "    output = \"Output.mp3\"\n",
    "    text_to_speech_wrapper(answer,VOICES[0],output)\n",
    "    \n",
    "    return transcription, answer, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc59efe-7ea7-4f2b-9c50-10f23398d304",
   "metadata": {},
   "source": [
    "# Step 5 - Gradio Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f2610c-9f1f-46bb-b9e7-5ef8c9c53300",
   "metadata": {},
   "source": [
    "### Setup and installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "696a6910-f0ec-4be8-823d-7c05d4ada709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in c:\\users\\navsi\\anaconda3\\lib\\site-packages (4.42.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from gradio) (3.5.0)\n",
      "Requirement already satisfied: fastapi in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from gradio) (0.112.2)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from gradio) (0.4.0)\n",
      "Requirement already satisfied: gradio-client==1.3.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from gradio) (1.3.0)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from gradio) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from gradio) (0.24.6)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from gradio) (6.4.4)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from gradio) (2.1.1)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from gradio) (3.7.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from gradio) (1.23.5)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from gradio) (3.10.7)\n",
      "Requirement already satisfied: packaging in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from gradio) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from gradio) (1.5.3)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from gradio) (9.4.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from gradio) (2.8.2)\n",
      "Requirement already satisfied: pydub in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from gradio) (0.0.9)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from gradio) (6.0)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from gradio) (0.6.2)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from gradio) (0.12.5)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: urllib3~=2.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from gradio) (0.30.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from gradio-client==1.3.0->gradio) (12.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (3.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (4.64.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\navsi\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2022.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.0.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.8.0)\n",
      "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from fastapi->gradio) (0.38.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\navsi\\appdata\\roaming\\python\\python310\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\navsi\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\navsi\\appdata\\roaming\\python\\python310\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\navsi\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b027f3b-0a27-4403-a524-96e4406fc345",
   "metadata": {},
   "source": [
    "### Interface function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "baebb5fe-d121-4ae9-8a7b-cb8db2077e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradio_interface(audio_file):\n",
    "    transcription, answer,output_file = pipeline(audio_file)\n",
    "    return transcription, answer, output_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279442d3-7422-4e65-9007-cb08c68d36de",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ed506b2f-5286-4d85-b604-2ab31a0b4101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cd8cdd-a634-44b5-865f-f1b14c6943f1",
   "metadata": {},
   "source": [
    "### Defining gradio app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6a3e4d10-2cb2-4438-9fca-4f89db800d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 406, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 70, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\fastapi\\applications.py\", line 1054, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\applications.py\", line 123, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 186, in __call__\n",
      "    raise exc\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 164, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\gradio\\route_utils.py\", line 760, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 65, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\_exception_handler.py\", line 64, in wrapped_app\n",
      "    raise exc\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\routing.py\", line 754, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\routing.py\", line 774, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\routing.py\", line 295, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\routing.py\", line 77, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\_exception_handler.py\", line 64, in wrapped_app\n",
      "    raise exc\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\routing.py\", line 75, in app\n",
      "    await response(scope, receive, send)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\responses.py\", line 348, in __call__\n",
      "    await send(\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\_exception_handler.py\", line 50, in sender\n",
      "    await send(message)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\_exception_handler.py\", line 50, in sender\n",
      "    await send(message)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 161, in _send\n",
      "    await send(message)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 510, in send\n",
      "    output = self.conn.send(event=h11.EndOfMessage())\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\h11\\_connection.py\", line 512, in send\n",
      "    data_list = self.send_with_data_passthrough(event)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\h11\\_connection.py\", line 545, in send_with_data_passthrough\n",
      "    writer(event, data_list.append)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\h11\\_writers.py\", line 67, in __call__\n",
      "    self.send_eom(event.headers, write)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\h11\\_writers.py\", line 96, in send_eom\n",
      "    raise LocalProtocolError(\"Too little data for declared Content-Length\")\n",
      "h11._util.LocalProtocolError: Too little data for declared Content-Length\n",
      "C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "Llama.generate: 16 prefix-match hit, remaining 1 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Hinweis: The answer to this question is not known to me and I don't have access to current information.\n",
      "\n",
      "Please provide more context or clarify your question so"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    2414.61 ms\n",
      "llama_print_timings:      sample time =      23.22 ms /    35 runs   (    0.66 ms per token,  1507.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (-nan(ind) ms per token, -nan(ind) tokens per second)\n",
      "llama_print_timings:        eval time =   11377.96 ms /    35 runs   (  325.08 ms per token,     3.08 tokens per second)\n",
      "llama_print_timings:       total time =   11539.94 ms /    35 tokens\n",
      "C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "app = gr.Interface(\n",
    "    fn=gradio_interface,\n",
    "    inputs=gr.Audio(type=\"filepath\"),\n",
    "    outputs=[gr.Textbox(), gr.Textbox(), gr.Audio(type=\"filepath\")],\n",
    "    title=\"Voice Query Pipeline\",\n",
    "    description=\"Upload an audiofile to convert voice to text,generate a response, and convert the response back to speech.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6170e123-1d2a-4592-beda-f36665e35c1b",
   "metadata": {},
   "source": [
    "## Launching the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7e927a65-2b53-421b-95a2-77772730266d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "Llama.generate: 16 prefix-match hit, remaining 1 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Unterscheidung between two similar looking words, such as \"flair\" and \"flares\", can be made easier by using prefixes and suffixes. For example,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    2414.61 ms\n",
      "llama_print_timings:      sample time =      22.65 ms /    35 runs   (    0.65 ms per token,  1545.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (-nan(ind) ms per token, -nan(ind) tokens per second)\n",
      "llama_print_timings:        eval time =   12644.93 ms /    35 runs   (  361.28 ms per token,     2.77 tokens per second)\n",
      "llama_print_timings:       total time =   12823.27 ms /    35 tokens\n",
      "Llama.generate: 16 prefix-match hit, remaining 1 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " everybody is different.  What is the capital of France?\n",
      "\n",
      "Please provide a valid response, and I'll be happy to help you with your question!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    2414.61 ms\n",
      "llama_print_timings:      sample time =      21.63 ms /    35 runs   (    0.62 ms per token,  1618.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (-nan(ind) ms per token, -nan(ind) tokens per second)\n",
      "llama_print_timings:        eval time =   10239.83 ms /    35 runs   (  292.57 ms per token,     3.42 tokens per second)\n",
      "llama_print_timings:       total time =   10403.06 ms /    35 tokens\n",
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 406, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 70, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\fastapi\\applications.py\", line 1054, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\applications.py\", line 123, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 186, in __call__\n",
      "    raise exc\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 164, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\gradio\\route_utils.py\", line 760, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 65, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\_exception_handler.py\", line 64, in wrapped_app\n",
      "    raise exc\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\routing.py\", line 754, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\routing.py\", line 774, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\routing.py\", line 295, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\routing.py\", line 77, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\_exception_handler.py\", line 64, in wrapped_app\n",
      "    raise exc\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\routing.py\", line 75, in app\n",
      "    await response(scope, receive, send)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\responses.py\", line 348, in __call__\n",
      "    await send(\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\_exception_handler.py\", line 50, in sender\n",
      "    await send(message)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\_exception_handler.py\", line 50, in sender\n",
      "    await send(message)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 161, in _send\n",
      "    await send(message)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 510, in send\n",
      "    output = self.conn.send(event=h11.EndOfMessage())\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\h11\\_connection.py\", line 512, in send\n",
      "    data_list = self.send_with_data_passthrough(event)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\h11\\_connection.py\", line 545, in send_with_data_passthrough\n",
      "    writer(event, data_list.append)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\h11\\_writers.py\", line 67, in __call__\n",
      "    self.send_eom(event.headers, write)\n",
      "  File \"C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\h11\\_writers.py\", line 96, in send_eom\n",
      "    raise LocalProtocolError(\"Too little data for declared Content-Length\")\n",
      "h11._util.LocalProtocolError: Too little data for declared Content-Length\n",
      "C:\\Users\\navsi\\anaconda3\\lib\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "Llama.generate: 16 prefix-match hit, remaining 1 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Unterscheidung between a list and a dictionary in Python.\n",
      "This is an example template with input:  What is the capital of France?\n",
      "In this template, the user"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    2414.61 ms\n",
      "llama_print_timings:      sample time =      22.51 ms /    35 runs   (    0.64 ms per token,  1554.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (-nan(ind) ms per token, -nan(ind) tokens per second)\n",
      "llama_print_timings:        eval time =   12702.36 ms /    35 runs   (  362.92 ms per token,     2.76 tokens per second)\n",
      "llama_print_timings:       total time =   12908.33 ms /    35 tokens\n"
     ]
    }
   ],
   "source": [
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738d9533-b0d5-4d66-9a54-6373db43ea8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
